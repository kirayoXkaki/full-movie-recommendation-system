{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a5237cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为用户 1 推荐的电影：\n",
      "1. Four Rooms\n",
      "2. Ariel\n",
      "3. Shadows in Paradise\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def user_based_recommender(ratings_file, movies_file, user_id, top_n=10, similar_k=5):\n",
    "    \"\"\"\n",
    "    用基于用户的协同过滤方法为指定用户推荐电影。\n",
    "\n",
    "    参数：\n",
    "    - ratings_file: str, 评分数据路径（如 'ratings_small.csv'）\n",
    "    - movies_file: str, 电影元数据路径（如 'movies_metadata.csv'）\n",
    "    - user_id: int, 要推荐的用户 ID\n",
    "    - top_n: int, 返回推荐的电影数量\n",
    "    - similar_k: int, 使用最相似的 k 个用户做加权推荐\n",
    "\n",
    "    返回：\n",
    "    - List of recommended movie titles\n",
    "    \"\"\"\n",
    "    # 读取评分和电影信息\n",
    "    ratings = pd.read_csv(ratings_file)\n",
    "    movies = pd.read_csv(movies_file, low_memory=False)\n",
    "    ratings = ratings.dropna()\n",
    "\n",
    "    # 创建用户-电影评分矩阵\n",
    "    user_movie_matrix = ratings.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "    matrix_filled = user_movie_matrix.fillna(0)\n",
    "\n",
    "    # 用户之间的余弦相似度\n",
    "    user_similarity = cosine_similarity(matrix_filled)\n",
    "    sim_df = pd.DataFrame(user_similarity, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
    "\n",
    "    # 找出最相似的 K 个用户（排除自己）\n",
    "    similar_users = sim_df[user_id].sort_values(ascending=False)[1:similar_k+1]\n",
    "    \n",
    "    # 获取这些相似用户的评分数据\n",
    "    similar_ratings = user_movie_matrix.loc[similar_users.index]\n",
    "    \n",
    "    # 加权评分（相似度 * 评分）\n",
    "    weighted_ratings = similar_ratings.T.dot(similar_users)\n",
    "    weighted_avg = weighted_ratings / similar_users.sum()\n",
    "\n",
    "    # 去掉该用户已经评分过的电影\n",
    "    watched = user_movie_matrix.loc[user_id].dropna().index\n",
    "    recommendations = weighted_avg.drop(watched, errors='ignore').sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    # 匹配电影名称（注意要做类型转换）\n",
    "    movies['id'] = pd.to_numeric(movies['id'], errors='coerce')\n",
    "    recommended_titles = movies[movies['id'].isin(recommendations.index)]['title'].dropna().tolist()\n",
    "\n",
    "    return recommended_titles\n",
    "\n",
    "\n",
    "recs = user_based_recommender(\n",
    "    ratings_file='movielens_dataset/ratings_small.csv',\n",
    "    movies_file='movielens_dataset/movies_metadata.csv',\n",
    "    user_id=1,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(\"为用户 1 推荐的电影：\")\n",
    "for i, title in enumerate(recs, 1):\n",
    "    print(f\"{i}. {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c0672",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d94a7938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44512, 5000)\n",
      "4375     Everybody's All-American\n",
      "35664       See You in Montevideo\n",
      "13036                 The Express\n",
      "11209                  Invincible\n",
      "40724    I'm a Standard Supporter\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # 用于解析字符串形式的 JSON\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('movielens_dataset/movies_metadata.csv', low_memory=False)\n",
    "\n",
    "# 只保留有用的列：title、overview 和 genres\n",
    "df = df[['title', 'overview', 'genres']]\n",
    "\n",
    "# 去除缺失的文本\n",
    "df = df.dropna(subset=['overview'])\n",
    "\n",
    "# genres 是一个字符串化的 JSON，我们把它变成关键词列表\n",
    "def parse_genres(genre_str):\n",
    "    try:\n",
    "        genres = ast.literal_eval(genre_str)\n",
    "        return \" \".join([g['name'] for g in genres])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df['genres'] = df['genres'].apply(parse_genres)\n",
    "\n",
    "# 合并 overview 和 genres 成一个文本字段用于文本建模\n",
    "df['content'] = df['overview'] + \" \" + df['genres']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 使用 TF-IDF 处理文本，限制最大词汇数量\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf.fit_transform(df['content'])\n",
    "\n",
    "print(tfidf_matrix.shape)  # (电影数量, 特征维度)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 计算电影之间的余弦相似度\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 构建电影索引：标题 -> 索引\n",
    "indices = pd.Series(df.index, index=df['title']).drop_duplicates()\n",
    "\n",
    "# 推荐函数\n",
    "def recommend(title, top_n=5):\n",
    "    matches = indices[indices.index == title]\n",
    "    if matches.empty:\n",
    "        print(\"电影没找到\")\n",
    "        return\n",
    "    idx = matches.iloc[0]  # 取第一个匹配项\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_n+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df['title'].iloc[movie_indices]\n",
    "\n",
    "# 示例：输入一部电影名称\n",
    "print(recommend(\"The Dark Knight\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee541",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
